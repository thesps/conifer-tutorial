{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91b96cc-7d99-434a-8771-ffbfa5dc7fd4",
   "metadata": {},
   "source": [
    "# VHDL Implementation\n",
    "\n",
    "In this section we will use the conifer VHDL backend to generate some model-specific hand-written VHDL for the model from part 1. We will show how to use it analagously to the HLS backend, but the main purpose is to look at the VHDL and compare with the HLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2a442-3712-47dc-bb2d-18bb2daadc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import conifer\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# enable more output from conifer\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "# create a random seed at we use to make the results repeatable\n",
    "seed = int('fpga_tutorial'.encode('utf-8').hex(), 16) % 2**31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccf517-5ea7-4158-9fa7-cd3fc25c94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFN CNAF Setup\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2023.2/tps/lnx64/gcc-9.3.0/bin/:' + '/tools/Xilinx/Vitis_HLS/2023.2/bin/:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/tools/Xilinx/Vitis_HLS/2023.2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd863c-51bd-4d8b-9283-56575087d913",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We create our template configuration much the same as in part 1. Note that now we specify `vhdl` for the backend. We also set a different output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc4daf-8b08-43fb-b2b7-8c09ef1eec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conifer.backends.vhdl.auto_config()\n",
    "\n",
    "# print the config\n",
    "print('Default Configuration\\n' + '-' * 50)\n",
    "print(json.dumps(cfg, indent=2))\n",
    "print('-' * 50)\n",
    "\n",
    "# modify the config\n",
    "cfg['OutputDir'] = 'prj_conifer_part_1b_vhdl'\n",
    "cfg['XilinxPart'] = 'xcu50-fsvh2104-2-e'\n",
    "\n",
    "# print the config again\n",
    "print('Modified Configuration\\n' + '-' * 50)\n",
    "print(json.dumps(cfg, indent=2))\n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0f559-a64c-42b7-8301-a62721cc413d",
   "metadata": {},
   "source": [
    "## Write Project\n",
    "We load the model trained in part 1, applying the new configuration we defined in the previous cell, then write the VHDL project to the specified directory.\n",
    "\n",
    "Take a look at the generated code, especially under firmware! Compare in particular `prj_conifer_part_1b_vhdl/firmware/Tree.vhd` with `Tree::decision_function` in `prj_conifer_part_1/firmware/BDT.h` which are the two implementations of the same algorithm.\n",
    "\n",
    "The output of `tree prj_conifer_part_1b_vhdl` is below:\n",
    "\n",
    "```\n",
    ".\n",
    "├── firmware\n",
    "│   ├── AddReduce.vhd\n",
    "│   ├── Arrays0.vhd\n",
    "│   ├── BDTTestbench.vhd\n",
    "│   ├── BDTTop.vhd\n",
    "│   ├── BDT.vhd\n",
    "│   ├── Constants.vhd\n",
    "│   ├── SimulationInput.vhd\n",
    "│   ├── SimulationOutput.vhd\n",
    "│   ├── TestUtil.vhd\n",
    "│   ├── Tree.vhd\n",
    "│   └── Types.vhd\n",
    "├── my_prj.json\n",
    "├── SimulationInput.txt\n",
    "├── synth.tcl\n",
    "└── xsim_compile.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a64d8b-0506-4359-9689-d5e81b213dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model = conifer.model.load_model('prj_conifer_part_1/my_prj.json', new_config=cfg)\n",
    "conifer_model.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca385450-f6cb-420b-9969-23ba2d9b569e",
   "metadata": {},
   "source": [
    "## Compile\n",
    "\n",
    "Now we compile the code for simulation, as in part 1. We need to use a VHDL simulator. This is more similar to the 'cosimulation' step that we've used with HLS than the 'c simulation' since it's clock cycle accurate. conifer supports `xsim` (Vivado built-in simulator), `modelsim`, and `ghdl`. We will use `xsim` since it is installed alongside Vivado. \n",
    "\n",
    "The testbench that we compile and simulate is provided by conifer. It reads data from a file (that we will write later), provides that as stimulus to the BDT module, and writes data to another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c56357-1a0f-43db-9b72-6dac2ca30814",
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095fd67-351d-454c-9ea3-81629c6bae56",
   "metadata": {},
   "source": [
    "## Simulate\n",
    "\n",
    "Run the simulation to perform inference. When we call `decision_function` for this VHDL backend model, firstly the data is written to a file. Next the simulation is invoked using `xsim`, which writes the test results to another file. Then we read back the data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369640d-9ac1-49aa-a56e-78148f5039af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('moons_dataset/X_test.npy')\n",
    "y_vhdl = conifer_model.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1930c-507c-4579-8e07-54f27b204a70",
   "metadata": {},
   "source": [
    "## Compare\n",
    "\n",
    "Load the model again but specifying the conifer Python backend that is useful for quick checking. Then we print out the results to hopefully see that they're similar (remember the VHDL is still using fixed-point data and the Python is using float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b585b0b-df28-46a2-a7ce-be4d626f4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_cfg = {'backend' : 'py', 'output_dir' : 'dummy', 'project_name' : 'dummy'}\n",
    "conifer_py_model = conifer.model.load_model('prj_conifer_part_1/my_prj.json', new_config=py_cfg)\n",
    "y_py = conifer_py_model.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd9ee5-1381-4478-80e4-11310572271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac5255-d7a5-4f5a-acbe-78c13df8b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vhdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a82b51-bd5c-460a-93ce-8152f6977981",
   "metadata": {},
   "source": [
    "## Build\n",
    "\n",
    "We can synthesize the VHDL and generate a utilisation report. This synthesis will take a minute or two. Then we read the synthesis reports. Compare the LUT and FF usage from the VHDL backend model report with those from the `'vsynth'` section of the HLS model report from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f8e05-f54e-4837-91c9-83e4e7970c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d7488-86f9-4cb2-87c8-268d7a39169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model.read_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5815b-5111-4915-8739-6a644c2c27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = conifer.model.load_model('prj_conifer_part_1/my_prj.json')\n",
    "hls_model.read_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
