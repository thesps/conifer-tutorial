{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e209d7-6139-425e-abdb-7a36f52198bc",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/thesps/conifer/blob/master/conifer_v1.png?raw=true\" width=\"250\" alt=\"conifer\" />\n",
    "\n",
    "In this notebook we will learn how to load BDTs onto the `conifer` FPU using the model from `part_1`.\n",
    "\n",
    "We'll target Xilinx the Alveo U50 card and a prebuilt FPU binary with 100 Tree Engines. First we download that binary from the conifer website.\n",
    "\n",
    "<img src=\"https://www.xilinx.com/content/dam/xilinx/imgs/kits/U50_Hero_1_Bracket.png\" width=250 alt=\"U50\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bee85-2908-4fc4-a888-88e497042e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ssummers.web.cern.ch/conifer/downloads/v1.4/alveo/u50_gen3x16_xdma_5_202210_1/fpu_100TE_512N_DS.xclbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201d2f5-0085-40d3-b64b-ce1b47757a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import conifer\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "# enable more output from conifer\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel('DEBUG')\n",
    "\n",
    "# create a random seed at we use to make the results repeatable\n",
    "seed = int('fpga_tutorial'.encode('utf-8').hex(), 16) % 2**31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92453d-2e09-478e-b516-75736635287f",
   "metadata": {},
   "source": [
    "# Forest Processing Unit\n",
    "\n",
    "Now we will execute of the same model on the same Alveo card, but this time using the reconfigurable `conifer FPU` rather than the static binary we previously used.\n",
    "\n",
    "We need to load our model in two phases: firstly load the FPU binary onto the FPGA, then load a model onto the FPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351c4df-b6b1-4ab4-b529-f4a84c0e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpu = conifer.backends.fpu.runtime.AlveoDriver('fpu_100TE_512N_DS.xclbin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671f9a2-865d-4afa-93bb-725172d22ab5",
   "metadata": {},
   "source": [
    "### FPU Config\n",
    "The configuration used to build the FPU binary is stored as a string as part of the binary itself. When we created the driver above, the configuration was read from the device, and below we print it. The key constraints that will restrict the size of model we can deploy are the number of Tree Engines, the number of nodes per TE, and the number of features.\n",
    "\n",
    "**Note**: we can only load one binary onto the FPGA at any time, so we cannot keep the `model_u50` above loaded at the same time as the `fpu` below. Save any result data (e.g. test data and predictions) to files in order to make comparisons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c2606-b1b1-42c1-b765-2d158e0fcfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpu.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4748ab5-c16d-4e85-9875-8b9ab2f4627f",
   "metadata": {},
   "source": [
    "## Load model part 1\n",
    "Now we have loaded the FPU onto the FPGA, we can load a model onto the FPU's node memories. We need to provide the FPU configuration when we convert the model in order to 'compile' the model into FPU DecisionNode data matching the target architecture.\n",
    "Specifically we need to set the `'FPU'` section of the `fpu` backend configuration. We can load this from the JSON file saved with the FPU build if we have it, or in this case we use the configuration that we read from the device itself.\n",
    "\n",
    "If we are using an FPU with the 'dynamic scaler', scale factors for the features will be derived at this step. This step is currently a bit too aggressive, so we do a hack to un-apply the auto-derived scaled, and then apply some more reasonable ones.\n",
    "\n",
    "**Note** there is no communication with the FPGA at this step, this is all Python running on the host PC.\n",
    "\n",
    "**Note** the 'compilation' done by conifer is quite simple, just reordering and packing the model data into bits. It is quite fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1ef59-f60b-47d3-883e-03f8b2409bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conifer.backends.fpu.auto_config()\n",
    "cfg['FPU'] = fpu.config\n",
    "model_fpu = conifer.model.load_model('prj_conifer_part_1/my_prj.json', new_config=cfg)\n",
    "model_fpu.scale(1./model_fpu.threshold_scale, model_fpu.score_scale) # unscale\n",
    "model_fpu.scale(1000, 1000)                                          # rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9c223-3e33-4dbf-8faf-8f98b213d15f",
   "metadata": {},
   "source": [
    "## Load model part 2\n",
    "\n",
    "Now we download the model onto the FPU (that is already loaded onto the FPGA). As with the static accelerator, we specify the batch size in order to allocate buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ed461-668f-447e-8472-402fbff74205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fpu.attach_device(fpu, batch_size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c709a2-65d0-483d-94bd-d636f9ce9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('moons_dataset/X_test.npy').astype('float32')\n",
    "y_test = np.load('moons_dataset/y_test.npy')\n",
    "model_py = conifer.model.load_model('prj_conifer_part_2/my_prj.json', new_config={'backend':'py','output_dir':'dummy','project_name':'dummy'})\n",
    "y_py = model_py.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83cd60-76a3-48c6-aa50-ebf2e4221d3f",
   "metadata": {},
   "source": [
    "### Do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dea429-d585-4bee-b558-68f69cb4693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fpu = model_fpu.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3011e76-a5ae-4a3b-98f4-58fd92739870",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model('prj_conifer_part_1/xgboost_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da8249-c4e6-4734-a960-e364382a499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb = xgb_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f6211-f9c8-47a4-aa4f-c949dc613cbd",
   "metadata": {},
   "source": [
    "## Compare\n",
    "\n",
    "Now we'll plot the decision boundary again, this time comparing the FPU to xgboost output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da46752-12cb-4549-bdec-1cec9d5ea302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 1000x1000 grid of points in the feature space\n",
    "X_mesh = np.meshgrid(np.linspace(-3, 3, 1000), np.linspace(-3, 3, 1000))\n",
    "# reshape them for inference\n",
    "X_grid = np.vstack([X_mesh[0].ravel(), X_mesh[1].ravel()]).T.astype('float32')\n",
    "model_fpu.attach_device(fpu, batch_size=X_grid.shape[0]) # reinitialize the FPU with the batch size of the full dataset\n",
    "# run emulated inference, compute the class probability, reshape to 1000x1000 grid\n",
    "y_hls_mesh = np.reshape(expit(model_fpu.decision_function(X_grid)), X_mesh[0].shape)\n",
    "# run the xgboost prediction on the same grid\n",
    "y_xgb_mesh = np.reshape(xgb_model.predict_proba(X_grid)[:,1], X_mesh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dd1ca-6c34-43f2-bf68-1b9ce80b20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the boundaries, and the difference\n",
    "f, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "# plot HLS\n",
    "display = DecisionBoundaryDisplay(xx0=X_mesh[0], xx1=X_mesh[1], response=y_hls_mesh)\n",
    "display.plot(cmap='PiYG', ax=axs[0])\n",
    "axs[0].scatter(X_test[:,0][:200], X_test[:,1][:200], c=y_test[:200], cmap='PiYG', edgecolors='k')\n",
    "axs[0].set_title('FPU')\n",
    "\n",
    "# plot the XGBoost\n",
    "display = DecisionBoundaryDisplay(xx0=X_mesh[0], xx1=X_mesh[1], response=y_xgb_mesh)\n",
    "display.plot(cmap='PiYG', ax=axs[1])\n",
    "axs[1].scatter(X_test[:,0][:200], X_test[:,1][:200], c=y_test[:200], cmap='PiYG', edgecolors='k')\n",
    "axs[1].set_title('XGBoost')\n",
    "\n",
    "# plot the difference\n",
    "pcm = axs[2].pcolormesh(X_mesh[0], X_mesh[1], y_xgb_mesh-y_hls_mesh)\n",
    "axs[2].set_title('XGBoost - HLS')\n",
    "f.colorbar(pcm)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e42649-d146-4e6f-b56d-7517058e9459",
   "metadata": {},
   "source": [
    "## Building FPU\n",
    "\n",
    "The Forest Processing Unit implementation is in HLS, and `conifer` also provides the interface to build a new architecture from a configuration. Now we will do that, building only the HLS C Synthesis part to take a look at the reports. \n",
    "\n",
    "The Alveo U50 is not in the default supported list of boards of conifer, so first of all we register that to conifer using the proper part number.\n",
    "\n",
    "Try changing some of the configuration (like the number of TEs, nodes, features etc). The configuration is printed at the end of the next cell, so you can see what options can be changed and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bf35c-a714-4e7f-98ee-07ad2dc792e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u50 = conifer.backends.boards.AlveoConfig.default_config()\n",
    "u50['xilinx_part'] = 'xcu50-fsvh2104-2-e'\n",
    "u50['platform'] = 'xilinx_u50_gen3x16_xdma_5_202210_1'\n",
    "u50['name'] = 'xilinx_u50_gen3x16_xdma_5_202210_1'\n",
    "u50 = conifer.backends.boards.AlveoConfig(u50)\n",
    "conifer.backends.boards.register_board_config(u50.name, u50)\n",
    "\n",
    "new_fpu_cfg = conifer.backends.fpu.FPUBuilder.default_cfg()\n",
    "new_fpu_cfg['output_dir'] = 'my_conifer_fpu'\n",
    "new_fpu_cfg['project_name'] = 'custom_fpu'\n",
    "new_fpu_cfg['tree_engines'] = 42\n",
    "new_fpu_cfg['board'] = u50.name\n",
    "new_fpu_cfg['clock_period'] = 2.5\n",
    "new_fpu_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5142a-9da4-4831-9f88-d3995eac7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yavin setup\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vitis_HLS/2023.1/bin/:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/opt/Xilinx/Vitis_HLS/2023.1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167ccb9-c603-4be3-b75f-53626e649f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFN CNAF Setup\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2023.2/bin/:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/tools/Xilinx/Vitis_HLS/2023.2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436170c8-2d0e-4cdb-802a-cd3f03b86d90",
   "metadata": {},
   "source": [
    "### Run build\n",
    "Now we write the HLS project and necessary build scripts, then run the HLS C Synthesis. This will take a few minutes, then check the reports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7de76-fee9-49f4-8441-ba571cda2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpu_builder = conifer.backends.fpu.FPUBuilder(new_fpu_cfg)\n",
    "fpu_builder.write()\n",
    "fpu_builder.build(synth=True, bitfile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe21b5-3853-4fbd-8b10-6238430c5ddb",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Try out the FPU flexibility by training some more BDTs and carrying out inference on the FPGA using the conifer FPU we downloaded at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba70ac-af0e-4483-aa3e-c55546c44b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
