{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/thesps/conifer/blob/master/conifer_v1.png?raw=true\" width=\"250\" alt=\"conifer\" />\n",
    "\n",
    "In this notebook we will take the first steps with training a BDT with `xgboost`, then translating it to HLS code for FPGA with `conifer`\n",
    "\n",
    "Key concepts:\n",
    "- dataset creation\n",
    "- model training\n",
    "- model evaluation\n",
    "- `conifer` configuration and conversion\n",
    "- model emulation / re-evaluation\n",
    "- model synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFN CNAF Setup\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2023.2/tps/lnx64/gcc-9.3.0/bin/:' + '/tools/Xilinx/Vitis_HLS/2023.2/bin/:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/tools/Xilinx/Vitis_HLS/2023.2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import conifer\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# enable more output from conifer\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "# create a random seed at we use to make the results repeatable\n",
    "seed = int('fpga_tutorial'.encode('utf-8').hex(), 16) % 2**31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset\n",
    "For this first introduction we will create a synthetic random separable dataset with 2 variables from `scikit-learn` `make_moons`. You'll see where it gets the name when we plot it below. We make a crude train/test split, using some of the data for the model training and reserving the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=5000, noise=0.3, random_state=seed)\n",
    "X_train, X_test = X[:2500], X[2500:]\n",
    "y_train, y_test = y[:2500], y[2500:]\n",
    "\n",
    "# save to files\n",
    "os.makedirs('moons_dataset', exist_ok=True)\n",
    "np.save('moons_dataset/X_train.npy', X_train)\n",
    "np.save('moons_dataset/X_test.npy', X_test)\n",
    "np.save('moons_dataset/y_train.npy', y_train)\n",
    "np.save('moons_dataset/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dataset\n",
    "Visualise the dataset we just created. There are two variables that we plot on `(x,y)` and two classes that we show with colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap='PiYG', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a BDT\n",
    "We'll use `xgboost`'s `XGBClassifier` with:\n",
    "\n",
    "| Parameter | Explanation |\n",
    "| --- | --- |\n",
    "| `n_estimators=20` | 20 trees\n",
    "| `max_depth=3` | maximum tree depth of 3\n",
    "| `learning_rate=1.0` | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=20, max_depth=3, learning_rate=1.0,\n",
    "                        random_state=seed).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate performance\n",
    "Now we check whether the trained model is any good. Firstly we'll visualise the decision boundary which shows how the strength of the prediction varies across the parameter space. Where there is more overlap between the classes, the prediction is less certain.\n",
    "\n",
    "We plot a few of the test set examples on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionBoundaryDisplay.from_estimator(clf, X_test, cmap='PiYG')\n",
    "plt.scatter(X_test[:,0][:200], X_test[:,1][:200], c=y_test[:200], cmap='PiYG', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/thesps/conifer/blob/master/conifer_v1.png?raw=true\" width=\"250\" alt=\"conifer\" />\n",
    "\n",
    "Now we'll convert this model to FPGA firmware with `conifer`. We first need to create a configuration in the form of a dictionary. The quickest way to get started is to create a default configuration from the intended target backend (`xilinxhls` for us). Each backend may have different configuration options, so getting the configuration this way helps enumerate the possible options.\n",
    "\n",
    "We will print the configuration, modify it, and print it again. The modifications are:\n",
    "- set the `OutputDirectory` to something descriptive\n",
    "- set the `XilinxPart` to the part number of the FPGA on the Alveo U50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conifer.backends.xilinxhls.auto_config()\n",
    "\n",
    "# print the config\n",
    "print('Default Configuration\\n' + '-' * 50)\n",
    "print(json.dumps(cfg, indent=2))\n",
    "print('-' * 50)\n",
    "\n",
    "# modify the config\n",
    "cfg['OutputDir'] = 'prj_conifer_part_1'\n",
    "cfg['XilinxPart'] = 'xcu50-fsvh2104-2-e'\n",
    "\n",
    "# print the config again\n",
    "print('Modified Configuration\\n' + '-' * 50)\n",
    "print(json.dumps(cfg, indent=2))\n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and write\n",
    "Convert the `xgboost` model to a `conifer` one, and print the `help` to see what methods it implements.\n",
    "Then `write` the model, creating the specified output directory and writing all the HLS files to it. We also save the `xgboost` model itself.\n",
    "\n",
    "#### Other converters:\n",
    "`conifer` has converters for several popular BDT training libraries. Each one is used like: `conifer.converters.convert_from_<library>(model, config)`\n",
    "The converters are:\n",
    "- `sklearn`\n",
    "- `xgboost`\n",
    "- `tf_df`\n",
    "- `tmva`\n",
    "- `onnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model = conifer.converters.convert_from_xgboost(clf, cfg)\n",
    "help(conifer_model)\n",
    "conifer_model.write()\n",
    "clf.save_model('prj_conifer_part_1/xgboost_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore\n",
    "Browse the files in the newly created project directory to take a look at the HLS code.\n",
    "\n",
    "The output of `!tree prj_conifer_part_1` is:\n",
    "\n",
    "```\n",
    "prj_conifer_part_1/\n",
    "├── bridge.cpp\n",
    "├── build_hls.tcl\n",
    "├── firmware\n",
    "│   ├── BDT.cpp\n",
    "│   ├── BDT.h\n",
    "│   ├── my_prj.cpp\n",
    "│   ├── my_prj.h\n",
    "│   └── parameters.h\n",
    "├── hls_parameters.tcl\n",
    "├── my_prj.json\n",
    "├── my_prj_test.cpp\n",
    "├── tb_data\n",
    "└── vivado_synth.tcl\n",
    "\n",
    "2 directories, 11 files\n",
    "```\n",
    "\n",
    "- files under `firmware` are the HLS implementation of the model\n",
    "- `my_prj.json` is the saved converted `conifer` model that can be loaded again without the original `xgboost` model\n",
    "- `tcl` scripts are used for synthesizing the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulate\n",
    "Before starting the lengthy FPGA build process, we should validate that our conversion was successful and that the choice of precision was suitable. To do this we need to run the HLS C++ code on the CPU with some test data first. This is like the HLS C Simulation step, but rather than writing a C++ testbench and invoking `vitis_hls` to run `csim`, `conifer` implements Python bindings for the HLS.\n",
    "\n",
    "We first need to compile (which uses the C++ compiler), then we can make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hls = conifer_model.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n",
    "Now we check whether the emulated predictions are good. To do this, first we'll make the decision boundary for both the `conifer` and `xgboost` models, and also show the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 1000x1000 grid of points in the feature space\n",
    "X_mesh = np.meshgrid(np.linspace(-3, 3, 1000), np.linspace(-3, 3, 1000))\n",
    "# reshape them for inference\n",
    "X_grid = np.vstack([X_mesh[0].ravel(), X_mesh[1].ravel()]).T\n",
    "# run emulated inference, compute the class probability, reshape to 1000x1000 grid\n",
    "y_hls_mesh = np.reshape(expit(conifer_model.decision_function(X_grid)), X_mesh[0].shape)\n",
    "# run the xgboost prediction on the same grid\n",
    "y_xgb_mesh = np.reshape(clf.predict_proba(X_grid)[:,1], X_mesh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the boundaries, and the difference\n",
    "f, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "# plot HLS\n",
    "display = DecisionBoundaryDisplay(xx0=X_mesh[0], xx1=X_mesh[1], response=y_hls_mesh)\n",
    "display.plot(cmap='PiYG', ax=axs[0])\n",
    "axs[0].scatter(X_test[:,0][:200], X_test[:,1][:200], c=y_test[:200], cmap='PiYG', edgecolors='k')\n",
    "axs[0].set_title('HLS')\n",
    "\n",
    "# plot the XGBoost\n",
    "display = DecisionBoundaryDisplay(xx0=X_mesh[0], xx1=X_mesh[1], response=y_xgb_mesh)\n",
    "display.plot(cmap='PiYG', ax=axs[1])\n",
    "axs[1].scatter(X_test[:,0][:200], X_test[:,1][:200], c=y_test[:200], cmap='PiYG', edgecolors='k')\n",
    "axs[1].set_title('XGBoost')\n",
    "\n",
    "# plot the difference\n",
    "pcm = axs[2].pcolormesh(X_mesh[0], X_mesh[1], y_xgb_mesh-y_hls_mesh)\n",
    "axs[2].set_title('XGBoost - HLS')\n",
    "f.colorbar(pcm)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build\n",
    "Now we'll run the Vitis HLS and Vivado synthesis. HLS C Synthesis compiles our C++ to RTL, performing scheduling and resource mapping. Vivado synthesis synthesizes the RTL from the previous step into a netlist, and produces a more realistic resource estimation. The latency can't change during Vivado synthesis, it's fixed in the RTL description.\n",
    "\n",
    "After the build completes we can also browse the new log files and reports that are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_model.build(synth=True, vsynth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "If the synthesis completed successfuly, we can extract the key metrics from the reports and print them out.\n",
    "The section `\"vsynth\"` contains the report from the Vivado RTL synthesis, which is usually lower, and more realistic than the HLS report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = conifer_model.read_report()\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Improve\n",
    "The `conifer` model seems to follow the `xgboost` predictions quite well, but it could be better. Our `xgboost` predictions were made with `float` data, thresholds, and scores while the `conifer` HLS predictions used the default precision `ap_fixed<16,6>` (16 bit signed with 6 integer bits). But was that the best choice? Below we inspect the distribution of values of the different parts of the model: data, thresholds, and scores.\n",
    "\n",
    "Your exercise is to try some different choices of precision to see if we can better agreement between the `xgboost` and `conifer` predictions.\n",
    "You can use the plot below to get some ideas for precision might work. Try changing both the width and integer parts, and maybe using rounding and saturation modes e.g. `ap_fixed<13,5,AP_RND_CONV,AP_SAT>` for 13 bits signed with 5 integer bits, convergent rounding (aka half-even rounding), and saturation.\n",
    "\n",
    "Remake the performance comparison plots to see how things behave after your changes, and `build` the model again to see if there is any impact on resources & latency.\n",
    "\n",
    "**Tip 1:** you can change the three precisions `InputPrecision`, `ThresholdPrecision`, and `ScorePrecision` indepdendently. Create the default configuration with those like this: `conifer.backends.xilinxhls.auto_config(granularity='full')`\n",
    "\n",
    "**Tip 2:** you can create a new configuration, and apply it to the already converted model like this:\n",
    "```python\n",
    "new_config = conifer.backends.xilinxhls.auto_config(granularity='full')\n",
    "new_config['OutputDir'] = 'some_sensible_directory_name'\n",
    "... make some modifications\n",
    "conifer_model = conifer.model.load_model('prj_conifer_part_1/my_prj.json', new_config=new_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.array([t for trees_c in conifer_model.trees for tree in trees_c for t, f in zip(tree.threshold, tree.feature) if f != -2])\n",
    "scores = np.array([v for trees_c in conifer_model.trees for tree in trees_c for v, f in zip(tree.value, tree.feature) if f == -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po2_bins = 2**np.arange(-16,16,1,dtype='float')\n",
    "bin_width = (po2_bins[1:] - po2_bins[:1])/3\n",
    "hist_data, _ = np.histogram(np.abs(X_train.ravel()), bins=po2_bins, density=True)\n",
    "hist_thresholds, _ = np.histogram(np.abs(thresholds), bins=po2_bins, density=True)\n",
    "hist_scores, _ = np.histogram(np.abs(scores), bins=po2_bins, density=True)\n",
    "ylim = np.max([hist_data.max(), hist_thresholds.max(), hist_scores.max()])\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(po2_bins[:-1], hist_data, width=bin_width, alpha=0.5, label='data')\n",
    "plt.bar(po2_bins[:-1], hist_thresholds, width=bin_width, alpha=0.5, label='thresholds')\n",
    "plt.bar(po2_bins[:-1], hist_scores, width=bin_width, alpha=0.5, label='scores')\n",
    "plt.plot([2**-10, 2**-10], [0,ylim*1.2], '--k', label='LSB')\n",
    "plt.plot([2**5, 2**5], [0,ylim*1.2], '--b', label='MSB')\n",
    "plt.ylim((1e-5, ylim*1.2))\n",
    "plt.xscale('log', base=2)\n",
    "plt.semilogy()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_configuration = conifer.backends.xilinxhls.auto_config(granularity='full')\n",
    "new_configuration['InputPrecision'] = ... # up to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
